{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d868fb77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient</th>\n",
       "      <th>cancer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ALL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ALL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>ALL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>ALL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>ALL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient cancer\n",
       "0        1    ALL\n",
       "1        2    ALL\n",
       "2        3    ALL\n",
       "3        4    ALL\n",
       "4        5    ALL"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv('./Data/actual.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48564956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "536829a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ALL    47\n",
       "AML    25\n",
       "Name: cancer, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cancer'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7623065",
   "metadata": {},
   "source": [
    "#### Data Augmentation or Text Augmentation Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d62fa90",
   "metadata": {},
   "source": [
    "This is a good movie;\n",
    "Awesome movie\n",
    "Movie good\n",
    "I like the movie\n",
    "Enjoyed movie\n",
    "This is a nice film"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe1b117",
   "metadata": {},
   "source": [
    "pip install textaugment (metin arttiriciyi yÃ¼kle)\n",
    "WordNet is a dictionary for the English language, specifically designed for natural language processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fd940f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\aleyy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'xyz'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pip install textaugment\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from textaugment import Wordnet\n",
    "t= Wordnet()\n",
    "t.augment('xyz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "480a4918",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\aleyy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'There caboodle are lots of career options after learning AI'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Insertion\n",
    ">>> import nltk\n",
    ">>> nltk.download('wordnet')\n",
    "from textaugment import EDA\n",
    "t = EDA()\n",
    "t.random_insertion(\"There are lots of career options after learning AI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bad89154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'provide trainings to students and working professionals'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Deletion - Randomly remove each word in the sentence with probability p\n",
    "\n",
    "t = EDA()\n",
    "t.random_deletion(\"We provide trainings to students and working professionals\", p=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e59e1e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Piford professionals trainings to students and working provide'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Swap - randomly choose two words in the sentence and swap their positions.\n",
    "t.random_swap(\"Piford provide trainings to students and working professionals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "71a04bf9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nlpaug'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9560/3778493881.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# NLPAug offers three types of augmentation; Character level augmentation, Word level augmentation, Sentence level augmentation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mnlpaug\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maugmenter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchar\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnac\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnlpaug\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maugmenter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnaw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnlpaug\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maugmenter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentence\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnas\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'nlpaug'"
     ]
    }
   ],
   "source": [
    "# pip install nlpaug\n",
    "# NLPAug offers three types of augmentation; Character level augmentation, Word level augmentation, Sentence level augmentation\n",
    "\n",
    "import nlpaug.augmenter.char as nac\n",
    "import nlpaug.augmenter.word as naw\n",
    "import nlpaug.augmenter.sentence as nas\n",
    "import nlpaug.flow as nafc\n",
    "\n",
    "from nlpaug.util import Action\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b76bf6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "piford provide trainings to students and working professionals.\n"
     ]
    }
   ],
   "source": [
    "text = 'piford provide trainings to students and working professionals.'\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f40631bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nac' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9560/2281070431.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0maug\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnac\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOcrAug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0maugmented_texts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maug\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maugment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Original:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Augmented texts:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nac' is not defined"
     ]
    }
   ],
   "source": [
    "aug = nac.OcrAug()\n",
    "augmented_texts = aug.augment(text, n=3)\n",
    "print(\"Original:\")\n",
    "print(text)\n",
    "print(\"Augmented texts:\")\n",
    "print(augmented_texts)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
